<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>icmt on RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/icmt/</link><description>Recent content in icmt on RL4AA Collaboration | Homepage</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 23 Oct 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/icmt/index.xml" rel="self" type="application/rss+xml"/><item><title>Toward the Application of Reinforcement Learning to the Intensity Control of a Seeded Free-Electron Laser</title><link>https://RL4aa.github.io/posts/publications/bruchon2019toward/</link><pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/bruchon2019toward/</guid><description>N. Bruchon, G. Fenu, G. Gaio, M. Lonza, F. A. Pellegrino, E. Salvato
University of Trieste
23rd International Conference on Mechatronics Technology
Abstract The optimization of particle accelerators is a challenging task, and many different approaches have been proposed in years, to obtain an optimal tuning of the plant and to keep it optimally tuned despite drifts or disturbances. Indeed, the classical model-free approaches (such as Gradient Ascent or Extremum Seeking algorithms) have intrinsic limitations.</description></item></channel></rss>