<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>conference proceedings on RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/conference-proceedings/</link><description>Recent content in conference proceedings on RL4AA Collaboration | Homepage</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 22 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/conference-proceedings/index.xml" rel="self" type="application/rss+xml"/><item><title>Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World Training</title><link>https://RL4aa.github.io/posts/kaiser2022learningbased/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/kaiser2022learningbased/</guid><description>J. Kaiser, O. Stein, A. Eichler. Deutsches Elektronen-Synchrotron DESY. 39th International Conference on Machine Learning.
Abstract In recent work, it has been shown that reinforcement learning (RL) is capable of solving a variety of problems at sometimes super-human performance levels. But despite continued advances in the field, applying RL to complex real-world control and optimisation problems has proven difficult. In this contribution, we demonstrate how to successfully apply RL to the optimisation of a highly complex real-world machine – specifically a linear particle accelerator – in an only partially observable setting and without requiring training on the real machine.</description></item><item><title>Automated Intensity Optimisation Using Reinforcement Learning at LEIR</title><link>https://RL4aa.github.io/posts/madysa2022automated/</link><pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/madysa2022automated/</guid><description>N. Madysa, V. Kain, R. Alemany Fernandez, N. Biancacci, B. Goddard, F. M. Velotti. CERN. 13th Particle Accelerator Conference.
Abstract High intensities in the Low Energy Ion Ring (LEIR) at CERN are achieved by stacking several multi-turn injec- tions from the pre-accelerator Linac3. Up to seven consec- utive 200 μs long, 200 ms spaced pulses are injected from Linac3 into LEIR. Two inclined septa, one magnetic and one electrostatic, combined with a collapsing horizontal or- bit bump allows a 6-D phase space painting via a linearly ramped mean momentum along the Linac3 pulse and in- jection at high dispersion.</description></item><item><title>Toward the Application of Reinforcement Learning to the Intensity Control of a Seeded Free-Electron Laser</title><link>https://RL4aa.github.io/posts/bruchon2019toward/</link><pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/bruchon2019toward/</guid><description>N. Bruchon, G. Fenu, G. Gaio, M. Lonza, F. A. Pellegrino, E. Salvato. University of Trieste. 23rd International Conference on Mechatronics Technology.
Abstract The optimization of particle accelerators is a challenging task, and many different approaches have been proposed in years, to obtain an optimal tuning of the plant and to keep it optimally tuned despite drifts or disturbances. Indeed, the classical model-free approaches (such as Gradient Ascent or Extremum Seeking algorithms) have intrinsic limitations.</description></item></channel></rss>