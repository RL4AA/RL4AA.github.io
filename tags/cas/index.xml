<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>cas on RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/cas/</link><description>Recent content in cas on RL4AA Collaboration | Homepage</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 13 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/cas/index.xml" rel="self" type="application/rss+xml"/><item><title>Orbit Correction Based on Improved Reinforcement Learning Algorithm</title><link>https://RL4aa.github.io/posts/publications/chen2023orbit/</link><pubDate>Thu, 13 Apr 2023 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/chen2023orbit/</guid><description>Xiaolong Chen, Yongzhi Jia, Xin Qi, Zhijun Wang, and Yuan He.
Institute of Modern Physics, Chinese Academy of Sciences, Lanzhou 730000, People’s Republic of China
School of Nuclear Science and Technology, University of Chinese Academy of Sciences, Beijing 100049, People’s Republic of China Physical Review Accelerators and Beams.
Abstract Recently, reinforcement learning (RL) algorithms have been applied to a wide range of control problems in accelerator commissioning. In order to achieve efficient and fast control, these algorithms need to be highly efficient, so as to minimize the online training time.</description></item></channel></rss>