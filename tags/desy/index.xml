<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>desy on &lt;img src="imgs/rl4aa_logo.png"/> RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/desy/</link><description>Recent content in desy on &lt;img src="imgs/rl4aa_logo.png"/> RL4AA Collaboration | Homepage</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 06 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/desy/index.xml" rel="self" type="application/rss+xml"/><item><title>Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning</title><link>https://RL4aa.github.io/posts/publications/kaiser2023learning/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/kaiser2023learning/</guid><description>J. Kaiser1, C. Xu2, A. Eichler1, A. Santamaria Garcia2, O. Stein1, E. Bründermann2, W. Kuropka1, H. Dinter1, F. Mayet1, T. Vinatier1, F. Burkart1, H. Schlarb1
1Deutsches Elektronen-Synchrotron DESY, 2 Karlsruhe Institute of Technology KIT
arXiv
Abstract Online tuning of real-world plants is a complex optimisation problem that continues to require manual intervention by experienced human operators. Autonomous tuning is a rapidly expanding field of research, where learning-based methods, such as Reinforcement Learning-trained Optimisation (RLO) and Bayesian optimisation (BO), hold great promise for achieving outstanding plant performance and reducing tuning times.</description></item><item><title>Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World Training</title><link>https://RL4aa.github.io/posts/publications/kaiser2022learningbased/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/kaiser2022learningbased/</guid><description>J. Kaiser, O. Stein, A. Eichler
Deutsches Elektronen-Synchrotron DESY
39th International Conference on Machine Learning
Abstract In recent work, it has been shown that reinforcement learning (RL) is capable of solving a variety of problems at sometimes super-human performance levels. But despite continued advances in the field, applying RL to complex real-world control and optimisation problems has proven difficult. In this contribution, we demonstrate how to successfully apply RL to the optimisation of a highly complex real-world machine – specifically a linear particle accelerator – in an only partially observable setting and without requiring training on the real machine.</description></item><item><title>First Steps Toward an Autonomous Accelerator, A Common Project Between DESY and KIT</title><link>https://RL4aa.github.io/posts/publications/eichler2021first/</link><pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/eichler2021first/</guid><description>A. Eichler1, F. Burkart1, J. Kaiser1, W. Kuropka1, O. Stein1, E. Bründermann2, A. Santamaria Garcia2, C. Xu2
1Deutsches Elektronen-Synchrotron DESY, 2Karlsruhe Institute of Technology KIT
12th International Particle Accelerator Conference
Abstract Reinforcement learning algorithms have risen in pop-ularity in the accelerator physics community in recentyears, showing potential in beam control and in the opti-mization and automation of tasks in accelerator operation.The Helmholtz AI project “Machine Learning Toward Au-tonomous Accelerators” is a collaboration between DESYand KIT that works on investigating and developing rein-forcement learning applications for the automatic start-upof electron linear accelerators.</description></item><item><title>Physics-Enhanced Reinforcement Learning for Optimal Control</title><link>https://RL4aa.github.io/posts/publications/ivanov2021physicsenhanced/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/ivanov2021physicsenhanced/</guid><description>A. Ivanov, I. Agapov, A. Eichler, S. Tomin
Deutsches Elektronen Synchrotron DESY
12th International Particle Accelerator Conference
Abstract We propose an approach for incorporating acceleratorphysics models into reinforcement learning agents. The proposed approach is based on the Taylor mapping technique for the simulation of particle dynamics. The resulting computational graph is represented as a polynomial neural network and embedded into the traditional reinforcement learning agents. The application of the model is demonstrated in a nonlinear simulation model of beam transmission.</description></item></channel></rss>