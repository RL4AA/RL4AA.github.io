<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Simulation-Trained on RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/simulation-trained/</link><description>Recent content in Simulation-Trained on RL4AA Collaboration | Homepage</description><generator>Hugo -- 0.152.1</generator><language>en-us</language><lastBuildDate>Tue, 06 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/simulation-trained/index.xml" rel="self" type="application/rss+xml"/><item><title>Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning</title><link>https://RL4aa.github.io/posts/publications/kaiser2023learning/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/kaiser2023learning/</guid><description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;J. Kaiser&lt;sup&gt;1&lt;/sup&gt;, C. Xu&lt;sup&gt;2&lt;/sup&gt;, A. Eichler&lt;sup&gt;1&lt;/sup&gt;, A. Santamaria Garcia&lt;sup&gt;2&lt;/sup&gt;, O. Stein&lt;sup&gt;1&lt;/sup&gt;, E. Bründermann&lt;sup&gt;2&lt;/sup&gt;, W. Kuropka&lt;sup&gt;1&lt;/sup&gt;, H. Dinter&lt;sup&gt;1&lt;/sup&gt;, F. Mayet&lt;sup&gt;1&lt;/sup&gt;, T. Vinatier&lt;sup&gt;1&lt;/sup&gt;, F. Burkart&lt;sup&gt;1&lt;/sup&gt;, H. Schlarb&lt;sup&gt;1&lt;/sup&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;Deutsches Elektronen-Synchrotron DESY, &lt;sup&gt;2&lt;/sup&gt; Karlsruhe Institute of Technology KIT&lt;/p&gt;
&lt;p&gt;&lt;em&gt;arXiv&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Online tuning of real-world plants is a complex optimisation problem that continues to require manual intervention by experienced human operators. Autonomous tuning is a rapidly expanding field of research, where learning-based methods, such as Reinforcement Learning-trained Optimisation (RLO) and Bayesian optimisation (BO), hold great promise for achieving outstanding plant performance and reducing tuning times. Which algorithm to choose in different scenarios, however, remains an open question. Here we present a comparative study using a routine task in a real particle accelerator as an example, showing that RLO generally outperforms BO, but is not always the best choice. Based on the study&amp;rsquo;s results, we provide a clear set of criteria to guide the choice of algorithm for a given tuning task. These can ease the adoption of learning-based autonomous tuning solutions to the operation of complex real-world plants, ultimately improving the availability and pushing the limits of operability of these facilities, thereby enabling scientific and engineering advancements.&lt;/p&gt;</description></item><item><title>Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World Training</title><link>https://RL4aa.github.io/posts/publications/kaiser2022learningbased/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/kaiser2022learningbased/</guid><description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;J. Kaiser, O. Stein, A. Eichler&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Deutsches Elektronen-Synchrotron DESY&lt;/p&gt;
&lt;p&gt;&lt;em&gt;39th International Conference on Machine Learning&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;In recent work, it has been shown that reinforcement learning (RL) is capable of solving a variety of problems at sometimes super-human performance levels. But despite continued advances in the field, applying RL to complex real-world control and optimisation problems has proven difficult. In this contribution, we demonstrate how to successfully apply RL to the optimisation of a highly complex real-world machine – specifically a linear particle accelerator – in an only partially observable setting and without requiring training on the real machine. Our method outperforms conventional optimisation algorithms in both the achieved result and time taken as well as already achieving close to human-level performance. We expect that such automation of machine optimisation will push the limits of operability, increase machine availability and lead to a paradigm shift in how such machines are operated, ultimately facilitating advances in a variety of fields, such as science and medicine among many others.&lt;/p&gt;</description></item></channel></rss>