<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>conference article on &lt;img src="imgs/rl4aa_logo.png"/> RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/conference-article/</link><description>Recent content in conference article on &lt;img src="imgs/rl4aa_logo.png"/> RL4AA Collaboration | Homepage</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 01 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/conference-article/index.xml" rel="self" type="application/rss+xml"/><item><title>Ultra fast reinforcement learning demonstrated at CERN AWAKE</title><link>https://RL4aa.github.io/posts/publications/ultra_fast_rl_awake/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/ultra_fast_rl_awake/</guid><description>** Simon Hirlaender, Lukas Lamminger, Giovanni Zevi Della Porta, Verena Kain**
Abstract Reinforcement learning (RL) is a promising direction in machine learning for the control and optimisation of particle accelerators since it learns directly from experience without needing a model a-priori. However, RL generally suffers from low sample efficiency and thus training from scracth on the machine is often not an option. RL agents are usually trained or pre-tuned on simulators and then transferred to the real environment.</description></item></channel></rss>