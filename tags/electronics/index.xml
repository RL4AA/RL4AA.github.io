<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>electronics on RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/electronics/</link><description>Recent content in electronics on RL4AA Collaboration | Homepage</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 09 May 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/electronics/index.xml" rel="self" type="application/rss+xml"/><item><title>Basic Reinforcement Learning Techniques to Control the Intensity of a Seeded Free-Electron Laser</title><link>https://RL4aa.github.io/posts/publications/bruchon2020basic/</link><pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/bruchon2020basic/</guid><description>N. Bruchon1, G. Fenu1, G. Gaio2, M. Lonza2, F. H. O’Shea2, F. A. Pellegrino1, E. Salvato1
1University of Trieste, 2Elettra Sincrotrone Trieste
Electronics
Abstract Optimal tuning of particle accelerators is a challenging task. Many different approaches have been proposed in the past to solve two main problems—attainment of an optimal working point and performance recovery after machine drifts. The most classical model-free techniques (e.g., Gradient Ascent or Extremum Seeking algorithms) have some intrinsic limitations.</description></item></channel></rss>