<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Electronics on RL4AA Collaboration | Homepage</title><link>https://RL4aa.github.io/tags/electronics/</link><description>Recent content in Electronics on RL4AA Collaboration | Homepage</description><generator>Hugo -- 0.152.1</generator><language>en-us</language><lastBuildDate>Sat, 09 May 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://RL4aa.github.io/tags/electronics/index.xml" rel="self" type="application/rss+xml"/><item><title>Basic Reinforcement Learning Techniques to Control the Intensity of a Seeded Free-Electron Laser</title><link>https://RL4aa.github.io/posts/publications/bruchon2020basic/</link><pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate><guid>https://RL4aa.github.io/posts/publications/bruchon2020basic/</guid><description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;N. Bruchon&lt;sup&gt;1&lt;/sup&gt;, G. Fenu&lt;sup&gt;1&lt;/sup&gt;, G. Gaio&lt;sup&gt;2&lt;/sup&gt;, M. Lonza&lt;sup&gt;2&lt;/sup&gt;, F. H. O’Shea&lt;sup&gt;2&lt;/sup&gt;, F. A. Pellegrino&lt;sup&gt;1&lt;/sup&gt;, E. Salvato&lt;sup&gt;1&lt;/sup&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;University of Trieste, &lt;sup&gt;2&lt;/sup&gt;Elettra Sincrotrone Trieste&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Electronics&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Optimal tuning of particle accelerators is a challenging task. Many different approaches have been proposed in the past to solve two main problems—attainment of an optimal working point and performance recovery after machine drifts. The most classical model-free techniques (e.g., Gradient Ascent or Extremum Seeking algorithms) have some intrinsic limitations. To overcome those limitations, Machine Learning tools, in particular Reinforcement Learning (RL), are attracting more and more attention in the particle accelerator community. We investigate the feasibility of RL model-free approaches to align the seed laser, as well as other service lasers, at FERMI, the free-electron laser facility at Elettra Sincrotrone Trieste. We apply two different techniques—the first, based on the episodic Q-learning with linear function approximation, for performance optimization; the second, based on the continuous Natural Policy Gradient REINFORCE algorithm, for performance recovery. Despite the simplicity of these approaches, we report satisfactory preliminary results, that represent the first step toward a new fully automatic procedure for the alignment of the seed laser to the electron beam. Such an alignment is, at present, performed manually.&lt;/p&gt;</description></item></channel></rss>