<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.110.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>RL4AA Collaboration | Homepage</title><meta name=description content="Reinforcement Learning for Autonomous Accelerator Collaboration - https://github.com/RL4AA"><meta name=author content="RL4AA Collaboration"><link rel=canonical href=https://RL4aa.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><link rel=icon href=https://RL4aa.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://RL4aa.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://RL4aa.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://RL4aa.github.io/apple-touch-icon.png><link rel=mask-icon href=https://RL4aa.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://RL4aa.github.io/index.xml><link rel=alternate type=application/json href=https://RL4aa.github.io/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="RL4AA Collaboration | Homepage"><meta property="og:description" content="Reinforcement Learning for Autonomous Accelerator Collaboration - https://github.com/RL4AA"><meta property="og:type" content="website"><meta property="og:url" content="https://RL4aa.github.io/"><meta name=twitter:card content="summary"><meta name=twitter:title content="RL4AA Collaboration | Homepage"><meta name=twitter:description content="Reinforcement Learning for Autonomous Accelerator Collaboration - https://github.com/RL4AA"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"RL4AA Collaboration | Homepage","url":"https://RL4aa.github.io/","description":"Reinforcement Learning for Autonomous Accelerator Collaboration - https://github.com/RL4AA","thumbnailUrl":"https://RL4aa.github.io/favicon.ico","sameAs":["https://github.com/RL4AA","https://discord.gg/QtBMqsjWH2"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://RL4aa.github.io/ accesskey=h title="RL4AA Collaboration | Homepage (Alt + H)"><img src=https://RL4aa.github.io/imgs/rl4aa_logo.png alt aria-label=logo height=30>RL4AA Collaboration | Homepage</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://RL4aa.github.io/categories/announcements title=Announcements><span>Announcements</span></a></li><li><a href=https://RL4aa.github.io/categories/publications title=Publications><span>Publications</span></a></li><li><a href=https://RL4aa.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://RL4aa.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://RL4aa.github.io/contact/ title=Contact><span>Contact</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>RL4AA Collaboration</h1></header><div class=entry-content><p>Collaboration on Reinforcement Learning for Autonomous Accelerators</p><p> </p><h2 id=find-your-way-around-the-site>Find your way around the site</h2><ul><li><strong><a href=/categories/announcements>Announcements</a></strong> of new events and information</li><li><strong><a href=/categories/publications/>Publications</a></strong> about RL applied for particle accelerators</li><li><strong><a href=/contact/>Contact</a></strong> us to contribute or collaborate</li><li><strong><a href=/search/>Search</a></strong> for keywords directly</li><li><strong><a href=/archives>Archive</a></strong> to see all the posts</li></ul></div><footer class=entry-footer><div class=social-icons><a href=https://github.com/RL4AA target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=https://discord.gg/QtBMqsjWH2 target=_blank rel="noopener noreferrer me" title=Discord><svg xmlns="http://www.w3.org/2000/svg" viewBox="20 15 205 190" fill="currentcolor" stroke="none"><path d="M104.4 103.9c-5.7.0-10.2 5-10.2 11.1s4.6 11.1 10.2 11.1c5.7.0 10.2-5 10.2-11.1.1-6.1-4.5-11.1-10.2-11.1zm36.5.0c-5.7.0-10.2 5-10.2 11.1s4.6 11.1 10.2 11.1c5.7.0 10.2-5 10.2-11.1s-4.5-11.1-10.2-11.1z"/><path d="M189.5 20h-134C44.2 20 35 29.2 35 40.6v135.2c0 11.4 9.2 20.6 20.5 20.6h113.4l-5.3-18.5 12.8 11.9 12.1 11.2 21.5 19V40.6c0-11.4-9.2-20.6-20.5-20.6zm-38.6 130.6s-3.6-4.3-6.6-8.1c13.1-3.7 18.1-11.9 18.1-11.9-4.1 2.7-8 4.6-11.5 5.9-5 2.1-9.8 3.5-14.5 4.3-9.6 1.8-18.4 1.3-25.9-.1-5.7-1.1-10.6-2.7-14.7-4.3-2.3-.9-4.8-2-7.3-3.4-.3-.2-.6-.3-.9-.5-.2-.1-.3-.2-.4-.3-1.8-1-2.8-1.7-2.8-1.7s4.8 8 17.5 11.8c-3 3.8-6.7 8.3-6.7 8.3-22.1-.7-30.5-15.2-30.5-15.2.0-32.2 14.4-58.3 14.4-58.3 14.4-10.8 28.1-10.5 28.1-10.5l1 1.2c-18 5.2-26.3 13.1-26.3 13.1s2.2-1.2 5.9-2.9c10.7-4.7 19.2-6 22.7-6.3.6-.1 1.1-.2 1.7-.2 6.1-.8 13-1 20.2-.2 9.5 1.1 19.7 3.9 30.1 9.6.0.0-7.9-7.5-24.9-12.7l1.4-1.6s13.7-.3 28.1 10.5c0 0 14.4 26.1 14.4 58.3.0.0-8.5 14.5-30.6 15.2z"/></svg></a></div></footer></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/rl4aa24_poster.png alt="RL4AA'24 flyer."></figure><header class=entry-header><h2>📍 RL4AA'24 call for abstracts extended to 5 January. Exciting keynote speakers announced. Register now!</h2></header><div class=entry-content><p>The call for abstracts for the RL4AA'24 workshop, taking place 05 - 07 February 2024 in Salzburg, Austria, has been extended. Register for the workshop and submit your abstract until 5 January 2024!
We are also excited to announce our keynote speakers:
Antonin Raffin (German Aerospace Center) Felix Berkenkamp (Bosch Center for AI) For more information on the workshop, please see the official workshop website: https://rl4aa.github.io/RL4AA24/
To get directly to registration, please visit: https://indico....</p></div><footer class=entry-footer><span title='2023-12-22 00:00:00 +0000 UTC'>December 22, 2023</span>&nbsp;·&nbsp;95 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to 📍 RL4AA'24 call for abstracts extended to 5 January. Exciting keynote speakers announced. Register now!" href=https://RL4aa.github.io/posts/announcements/rl4aa24_last_chance/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/salzburg_stock_photo_2.png alt=Salzburg.></figure><header class=entry-header><h2>Registration is now open for RL4AA'24 taking place 05 - 07 February 2024 in Salzburg, Austria</h2></header><div class=entry-content><p>Announcing RL4AA'24 - Registration is open! Following up on the very successful RL4AA'23 workshop in Karlsruhe earlier this year, we are excited to announce the 2nd RL4AA workshop RL4AA'24, which will be held in Salzburg, Austria, from 05 - 07 February 2024. The workshop will be hosted at the Paris Lodron University of Salzburg. We are looking forward to an exciting workshop with many interesting talks and discussions on reinforcement learning for autonomous particle accelerators and hope to see you all in Salzburg!...</p></div><footer class=entry-footer><span title='2023-08-18 00:00:00 +0000 UTC'>August 18, 2023</span>&nbsp;·&nbsp;96 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to Registration is now open for RL4AA'24 taking place 05 - 07 February 2024 in Salzburg, Austria" href=https://RL4aa.github.io/posts/announcements/rl4aa24_announcement/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/kaiser2023learning.png alt="Simplified 3D illustration of the considered section of the ARES particle accelerator."></figure><header class=entry-header><h2>Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning</h2></header><div class=entry-content><p>J. Kaiser1, C. Xu2, A. Eichler1, A. Santamaria Garcia2, O. Stein1, E. Bründermann2, W. Kuropka1, H. Dinter1, F. Mayet1, T. Vinatier1, F. Burkart1, H. Schlarb1
1Deutsches Elektronen-Synchrotron DESY, 2 Karlsruhe Institute of Technology KIT
arXiv
Abstract Online tuning of real-world plants is a complex optimisation problem that continues to require manual intervention by experienced human operators. Autonomous tuning is a rapidly expanding field of research, where learning-based methods, such as Reinforcement Learning-trained Optimisation (RLO) and Bayesian optimisation (BO), hold great promise for achieving outstanding plant performance and reducing tuning times....</p></div><footer class=entry-footer><span title='2023-06-06 00:00:00 +0000 UTC'>June 6, 2023</span>&nbsp;·&nbsp;201 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning" href=https://RL4aa.github.io/posts/publications/kaiser2023learning/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/discord_logo.png alt="Discord logo."></figure><header class=entry-header><h2>The RL4AA Discord server is up!</h2></header><div class=entry-content><p>Good News! The RL4AA community is happy to announce its Discord server! If you are interested in discussing reinforcement learning applied to accelerators, please join for announcements (e.g. new publications), forum discussions, an open chat, and meeting rooms.
Hope to see you there!
https://discord.gg/QtBMqsjWH2</p></div><footer class=entry-footer><span title='2023-06-02 00:00:00 +0000 UTC'>June 2, 2023</span>&nbsp;·&nbsp;44 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to The RL4AA Discord server is up!" href=https://RL4aa.github.io/posts/announcements/discord_server/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/chen2023trendbased.png alt="Overview of the training loop and the structure of simulated environment"></figure><header class=entry-header><h2>Trend-Based SAC Beam Control Method with Zero-Shot in Superconducting Linear Accelerator</h2></header><div class=entry-content><p>X. Chen, X. Qi, C. Su, Y. He, Z. Wang, K. Sun, C. Jin, W. Chen, S. Liu, X. Zhao, D. Jia, M. Yi
Chinese Academy of Sciences
arXiv
Abstract The superconducting linear accelerator is a highly flexiable facility for modern scientific discoveries, necessitating weekly reconfiguration and tuning. Accordingly, minimizing setup time proves essential in affording users with ample experimental time. We propose a trend-based soft actor-critic(TBSAC) beam control method with strong robustness, allowing the agents to be trained in a simulated environment and applied to the real accelerator directly with zero-shot....</p></div><footer class=entry-footer><span title='2023-05-23 00:00:00 +0000 UTC'>May 23, 2023</span>&nbsp;·&nbsp;244 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to Trend-Based SAC Beam Control Method with Zero-Shot in Superconducting Linear Accelerator" href=https://RL4aa.github.io/posts/publications/chen2023trendbased/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/THPL038_f2.png alt="Overview of the steering method."></figure><header class=entry-header><h2>Ultra fast reinforcement learning demonstrated at CERN AWAKE</h2></header><div class=entry-content><p>** Simon Hirlaender, Lukas Lamminger, Giovanni Zevi Della Porta, Verena Kain**
Abstract Reinforcement learning (RL) is a promising direction in machine learning for the control and optimisation of particle accelerators since it learns directly from experience without needing a model a-priori. However, RL generally suffers from low sample efficiency and thus training from scracth on the machine is often not an option. RL agents are usually trained or pre-tuned on simulators and then transferred to the real environment....</p></div><footer class=entry-footer><span title='2023-05-01 00:00:00 +0000 UTC'>May 1, 2023</span>&nbsp;·&nbsp;233 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to Ultra fast reinforcement learning demonstrated at CERN AWAKE " href=https://RL4aa.github.io/posts/publications/ultra_fast_rl_awake/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/salzburg_stock_photo.jpg alt=Salzburg.></figure><header class=entry-header><h2>The 2nd RL4AA workshop 2024 will be held 05 - 07 February 2024 in Salzburg</h2></header><div class=entry-content><p>Good News - save the date! Our first workshop, RL4AA 2023, was very successful. Because of this, we are hoping to hold the 2nd RL4AA workshop in spring 2024 in Salzburg, Austria in 05 - 07 February 2024. Further details will follow soon.</p></div><footer class=entry-footer><span title='2023-04-27 00:00:00 +0000 UTC'>April 27, 2023</span>&nbsp;·&nbsp;43 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to The 2nd RL4AA workshop 2024 will be held 05 - 07 February 2024 in Salzburg" href=https://RL4aa.github.io/posts/announcements/rl4aa24_stay_tuned/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/velotti2023towards.png alt="AWAKE beamline showing location of the matching devices (actions) and the observation BTV."></figure><header class=entry-header><h2>Towards automatic setup of 18 MeV electron beamline using machine learning</h2></header><div class=entry-content><p>F. M. Velotti1, B. Goddard1, V. Kain1, R. Ramjiawan1, G. Z. Della Porta1 and S. Hirlaender2
1CERN, 2University of Salzburg
Machine Learning: Science and Technology
Abstract To improve the performance-critical stability and brightness of the electron bunch at injection into the proton-driven plasma wakefield at the AWAKE CERN experiment, automation approaches based on unsupervised machine learning (ML) were developed and deployed. Numerical optimisers were tested together with different model-free reinforcement learning (RL) agents....</p></div><footer class=entry-footer><span title='2023-04-27 00:00:00 +0000 UTC'>April 27, 2023</span>&nbsp;·&nbsp;189 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to Towards automatic setup of 18 MeV electron beamline using machine learning" href=https://RL4aa.github.io/posts/publications/velotti2023towards/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/chen2023orbit.png alt="Overview of the orbit correction method."></figure><header class=entry-header><h2>Orbit Correction Based on Improved Reinforcement Learning Algorithm</h2></header><div class=entry-content><p>X. Chen, Y. Jia, X. Qi, Z. Wang, Y. He
Chinese Academy of Sciences
Physical Review Accelerators and Beams
Abstract Recently, reinforcement learning (RL) algorithms have been applied to a wide range of control problems in accelerator commissioning. In order to achieve efficient and fast control, these algorithms need to be highly efficient, so as to minimize the online training time. In this paper, we incorporated the beam position monitor trend into the observation space of the twin delayed deep deterministic policy gradient (TD3) algorithm and trained two different structure agents, one based on physical prior knowledge and the other using the original TD3 network architecture....</p></div><footer class=entry-footer><span title='2023-04-13 00:00:00 +0000 UTC'>April 13, 2023</span>&nbsp;·&nbsp;327 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to Orbit Correction Based on Improved Reinforcement Learning Algorithm" href=https://RL4aa.github.io/posts/publications/chen2023orbit/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://RL4aa.github.io/imgs/rl4aa23/rl4aa23_group_photo.jpg alt="RL4AA23workshop photo"></figure><header class=entry-header><h2>RL4AA'23: 1st Collaboration Workshop on Reinforcement Learning for Autonomous Accelerators</h2></header><div class=entry-content><p>Reinforcement learning is the most difficult learning paradigms to understand and to efficiently use, but it holds a lot of promise in the field of accelerator physics. The applications of reinforcement learning to accelerators today are not very numerous yet, but the interest of the community is growing considerably. This is how the 1st collaboration workshop on Reinforcement Learning for Autonomous Accelerators (RL4AA'23) came to be! The AI4Accelerators team organized and hosted the workshop at KIT, gathering colleagues involved in reinforcement learning....</p></div><footer class=entry-footer><span title='2023-02-21 00:00:00 +0000 UTC'>February 21, 2023</span>&nbsp;·&nbsp;188 words&nbsp;·&nbsp;RL4AA Collaboration</footer><a class=entry-link aria-label="post link to RL4AA'23: 1st Collaboration Workshop on Reinforcement Learning for Autonomous Accelerators" href=https://RL4aa.github.io/posts/announcements/rl4aa23/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://RL4aa.github.io/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://RL4aa.github.io/>RL4AA Collaboration | Homepage</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>