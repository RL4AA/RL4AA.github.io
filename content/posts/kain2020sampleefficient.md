---
title: "Sample-efficient reinforcement learning for CERN accelerator control"
date: 2020-12-01
draft: false
tags: ["publication", "journal article", "cern"]
categories: "Publications"
ShowToc: false
TocOpen: false
weight: 10
cover:
    image: imgs/kain2020sampleefficient.png
    alt: "The RL paradigm as applied to particle accelerator control, showing the example of trajectory correction."
    caption: "The RL paradigm as applied to particle accelerator control, showing the example of trajectory correction."
    relative: false
---

_**Verena Kain, Simon Hirlander, Brennan Goddard, Francesco Maria Velotti, Giovanni Zevi Della Porta, Niky Bruchon, and Gianluca Valentino**._ CERN, University of Trieste, University of Malta. _Physical Review Accelerators and Beams._

## Abstract

Numerical optimization algorithms are already established tools to increase and stabilize the performance of particle accelerators. These algorithms have many advantages, are available out of the box, and can be adapted to a wide range of optimization problems in accelerator operation. The next boost in efficiency is expected to come from reinforcement learning algorithms that learn the optimal policy for a certain control problem and hence, once trained, can do without the time-consuming exploration phase needed for numerical optimizers. To investigate this approach, continuous model-free reinforcement learning with up to 16 degrees of freedom was developed and successfully tested at various facilities at CERN. The approach and algorithms used are discussed and the results obtained for trajectory steering at the AWAKE electron line and LINAC4 are presented. The necessary next steps, such as uncertainty aware model-based approaches, and the potential for future applications at particle accelerators are addressed.

**Read the paper:** [https://doi.org/10.1103/PhysRevAccelBeams.23.124801](https://doi.org/10.1103/PhysRevAccelBeams.23.124801)

**Contact:** [Verena Kain](mailto:verena.kain@cern.ch)
